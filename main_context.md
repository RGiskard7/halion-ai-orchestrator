# üß© HALion: Modular Intelligence Orchestrator - Documentaci√≥n T√©cnica

## üìÑ Visi√≥n General

OpenAI Modular MCP (Model-Context-Protocol) es una plataforma extensible para la creaci√≥n, gesti√≥n y despliegue de asistentes IA con capacidades personalizadas a trav√©s de herramientas modulares. El sistema implementa un enfoque arquitect√≥nico que permite a los modelos de lenguaje de OpenAI interactuar con funciones externas de forma estructurada y administrada.

> Este documento proporciona una visi√≥n t√©cnica completa del proyecto, su arquitectura, componentes y flujos de trabajo, sirviendo como referencia t√©cnica principal para desarrolladores.

## üéØ Objetivos del Proyecto

- **Extensibilidad**: Proporcionar una base robusta para construir asistentes IA personalizados
- **Modularidad**: Permitir la adici√≥n, modificaci√≥n y eliminaci√≥n de capacidades sin afectar al sistema central
- **Usabilidad**: Ofrecer una interfaz intuitiva tanto para usuarios finales como para administradores
- **Transparencia**: Registrar todas las interacciones y ejecuciones para an√°lisis y auditor√≠a
- **Seguridad**: Implementar buenas pr√°cticas para el manejo de credenciales y ejecuci√≥n de c√≥digo
- **Control**: Proporcionar gesti√≥n granular de herramientas y su comportamiento
- **Diagn√≥stico**: Facilitar la detecci√≥n y soluci√≥n de problemas mediante logs detallados

## üèóÔ∏è Arquitectura del Sistema

### Diagrama de Flujo Principal

```
Usuario ‚Üí Interfaz Streamlit ‚Üí Executor (chat_with_tools) ‚Üí OpenAI API
Usuario ‚Üí Interfaz Streamlit ‚Üí Chat Service (chat_with_tools) ‚Üí OpenAI API
                                       ‚Üì
                                  ¬øfunction_call?
                                       ‚Üì
                                     Si ‚Üí Tool Manager ‚Üí ¬øTool Activa? ‚Üí Herramienta
                                       ‚Üì                      ‚Üì
                                    Logger ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê Resultado
                                       ‚Üì
                              ¬øPost-procesado?
                                       ‚Üì
                                Si ‚Üí OpenAI ‚Üí Respuesta
                                No ‚Üí Resultado Directo
                                       ‚Üì
                                   Usuario
```

### Componentes Principales

#### 1. `app/main.py`

Interfaz de usuario construida con Streamlit que proporciona:

- **Chat con IA**: 
  - Interfaz conversacional con soporte para texto
  - Selecci√≥n de modelo (GPT-4, GPT-4-Turbo, GPT-3.5-Turbo)
  - Control avanzado de par√°metros (temperatura, max_tokens, top_p, penalties)
  - Opci√≥n de seed para reproducibilidad
  - Historial de conversaci√≥n persistente
  - Visualizaci√≥n de herramientas activas

- **Panel de Administraci√≥n**:
  - Gesti√≥n de herramientas (carga, recarga, creaci√≥n, edici√≥n, eliminaci√≥n)
  - Activaci√≥n/desactivaci√≥n individual de herramientas
  - Paginaci√≥n para visualizar grandes conjuntos de herramientas
  - Control de post-procesado por herramienta
  - Generaci√≥n autom√°tica de herramientas con IA
  - Detecci√≥n autom√°tica de variables de entorno en c√≥digo generado
  - Prompts especializados para function calling
  - Visualizaci√≥n y exportaci√≥n de logs
  - Administraci√≥n de variables de entorno con UI dedicada

#### 2. `app/core/executor.py`

Orquestador central que:

- Construye los mensajes para la API de OpenAI
- Incluye las definiciones de herramientas disponibles
- Procesa la respuesta y detecta llamadas a funciones
- Ejecuta las herramientas solicitadas
- Gestiona el post-procesado condicional de resultados
- Reincorpora los resultados seg√∫n configuraci√≥n
- Pasa par√°metros avanzados (seed, penalties, etc.) a la API
- Gestiona el estado de la conversaci√≥n y la l√≥gica de interacci√≥n con el LLM.

#### 3. `app/services/chat_service.py`

Orquestador central que:

- Construye los mensajes para la API de OpenAI
- Incluye las definiciones de herramientas disponibles
- Procesa la respuesta y detecta llamadas a funciones
- Ejecuta las herramientas solicitadas
- Gestiona el post-procesado condicional de resultados
- Reincorpora los resultados seg√∫n configuraci√≥n
- Pasa par√°metros avanzados (seed, penalties, etc.) a la API

#### 4. `app/core/tool_manager.py`

Gestor de herramientas que:

- Carga din√°micamente todas las herramientas desde el directorio `app/tools/`
- Mantiene un registro de herramientas activas/inactivas
- Gestiona el estado de post-procesado de cada herramienta
- Registra errores de carga para diagn√≥stico
- Proporciona acceso unificado a herramientas est√°ticas y din√°micas
- Genera logs detallados de depuraci√≥n durante la carga

#### 5. `app/core/tool_definition_registry.py`

Registro de herramientas din√°micas que:

- Permite definir herramientas en tiempo de ejecuci√≥n
- Soporta generaci√≥n autom√°tica mediante IA
- Compila c√≥digo Python desde la interfaz de usuario
- Persiste herramientas creadas din√°micamente a disco
- Gestiona el ciclo de vida de herramientas en memoria
- Valida el c√≥digo generado antes de registrarlo
- Maneja errores de importaci√≥n y compilaci√≥n

#### 6. `app/core/logger.py`

Sistema de registro que:

- Documenta cada ejecuci√≥n de herramienta
- Almacena metadatos, argumentos y resultados
- Proporciona funciones para exportar logs en JSON y CSV
- Facilita el an√°lisis y depuraci√≥n
- Mantiene un historial limitado para optimizar memoria

#### 7. `app/utils/env_manager.py`

Gestor de variables de entorno que:

- Lee y escribe en el archivo `.env`
- Permite a√±adir, modificar y eliminar variables
- Protege informaci√≥n sensible como API keys
- Proporciona mecanismos para recargar variables en tiempo de ejecuci√≥n
- Asegura disponibilidad de variables en el entorno activo

## üîÑ Flujos de Trabajo

### 1. Flujo de Conversaci√≥n

1. El usuario env√≠a un mensaje a trav√©s de la interfaz de chat
2. `app/views/chat_view.py` llama a `chat_with_tools()` en `app/core/executor.py`
2. `app/views/chat_view.py` llama a `chat_with_tools()` en `app/services/chat_service.py`
3. `executor.py` prepara el contexto y env√≠a la solicitud a OpenAI
3. `chat_service.py` prepara el contexto y env√≠a la solicitud a OpenAI
4. OpenAI determina si se necesita invocar una herramienta
5. Si es necesario:
   - Se verifica si la herramienta est√° activa
   - `executor.py` obtiene la herramienta de `app/core/tool_manager.py`
   - `chat_service.py` obtiene la herramienta de `app/core/tool_manager.py`
   - Se ejecuta la herramienta y se registra en `app/core/logger.py`
   - Si tiene post-procesado activado:
     - El resultado se env√≠a a GPT para contextualizaci√≥n
   - Si no tiene post-procesado:
     - El resultado se devuelve directamente
6. El usuario recibe la respuesta seg√∫n la configuraci√≥n

### 2. Flujo de Gesti√≥n de Herramientas

#### Carga Inicial:

1. Al iniciar la aplicaci√≥n, `app/core/tool_manager.py` escanea el directorio `app/tools/`
2. Cada archivo Python se importa y se registra su funci√≥n principal y schema
3. Se cargan las herramientas din√°micas previamente guardadas
4. Se aplica el estado de activaci√≥n seg√∫n `app/config/.tool_status.json`
5. Se generan logs detallados de errores o problemas durante la carga

#### Creaci√≥n con IA:

1. El usuario describe la herramienta en lenguaje natural
2. La IA genera:
   - Nombre y descripci√≥n
   - Schema JSON de par√°metros
   - C√≥digo Python de implementaci√≥n
   - Configuraci√≥n de post-procesado
3. Se detectan autom√°ticamente las variables de entorno necesarias
4. El usuario revisa, configura las variables y puede modificar la generaci√≥n
5. La herramienta se registra y persiste en disco

#### Creaci√≥n Manual:

1. El usuario define:
   - Nombre y descripci√≥n
   - Comportamiento de post-procesado
   - Schema JSON de par√°metros
   - C√≥digo Python
2. La herramienta se valida y registra
3. Opcionalmente se persiste a disco
4. Se marcan como activas autom√°ticamente

## üìÇ Estructura de Directorios

```
.
‚îú‚îÄ‚îÄ app/                         # Estructura modular de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ components/              # Componentes reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ controllers/             # L√≥gica de controladores
‚îÇ   ‚îú‚îÄ‚îÄ views/                   # Vistas de la interfaz
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin_view.py        # Panel de administraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_view.py         # Interfaz de chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools_view.py        # Gesti√≥n de herramientas 
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Modelos de datos
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # Utilidades
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai_generation.py     # Generaci√≥n de herramientas/toolchains con IA
‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Funcionalidades centrales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_definition_registry.py  # Registro y gesti√≥n de archivos de tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py          # Orquestador de OpenAI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py            # Sistema de logs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_manager.py      # Gesti√≥n de herramientas
‚îÇ   ‚îú‚îÄ‚îÄ services/                # L√≥gica de servicios (ej. chat)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat_service.py      # Servicio principal de chat
‚îÇ   ‚îú‚îÄ‚îÄ tools/                   # Herramientas disponibles
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Archivos de configuraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .tool_status.json    # Estado de activaci√≥n de herramientas
‚îÇ   ‚îî‚îÄ‚îÄ debug_logs/              # Logs espec√≠ficos de la app
‚îÇ       ‚îú‚îÄ‚îÄ file_creation_debug.log  # Registro detallado de errores
‚îÇ       ‚îî‚îÄ‚îÄ tool_calls.log       # Registro de invocaciones a herramientas
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ assets/                  # Recursos visuales (im√°genes, iconos)
‚îÇ   ‚îî‚îÄ‚îÄ images/                  # Im√°genes para documentaci√≥n
‚îú‚îÄ‚îÄ .env                         # Variables de entorno (privado)
‚îú‚îÄ‚îÄ .env.example                 # Plantilla de variables
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias
‚îú‚îÄ‚îÄ pyproject.toml               # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ run.py                       # Script de ejecuci√≥n simplificado
‚îú‚îÄ‚îÄ main_context.md              # Arquitectura y contexto t√©cnico
‚îî‚îÄ‚îÄ roadmap.md                   # Plan de desarrollo
```

## üîå Integraci√≥n de Herramientas

### Anatom√≠a de una Herramienta

Cada herramienta consta de dos componentes principales:

1. **Funci√≥n Python**: Implementa la l√≥gica de la herramienta
2. **Schema JSON**: Define la interfaz, par√°metros y comportamiento

```python
# Ejemplo: tools/saludar.py

def saludar(nombre, formal=False):
    """
    Genera un saludo personalizado seg√∫n el nombre y formalidad.
    
    Args:
        nombre (str): Nombre de la persona a saludar
        formal (bool, optional): Si el saludo debe ser formal. Defaults to False.
        
    Returns:
        str: Saludo generado
    """
    if formal:
        return f"Estimado/a {nombre}, un placer saludarle."
    return f"¬°Hola {nombre}! ¬øC√≥mo est√°s?"

schema = {
  "name": "saludar",
  "description": "Genera un saludo personalizado",
  "postprocess": True,  # Controla si la IA procesa el resultado
  "parameters": {
    "type": "object",
    "properties": {
      "nombre": {"type": "string", "description": "Nombre de la persona"},
      "formal": {"type": "boolean", "description": "Si el saludo debe ser formal"}
    },
    "required": ["nombre"]
  }
}
```

### Ejemplo Avanzado: Integraci√≥n con MongoDB

```python
# Ejemplo: tools/get_hotel_info.py

from typing import Dict, Optional
from dotenv import load_dotenv
from pymongo import MongoClient
import json
import os

load_dotenv()

def get_hotel_info(hotel_name: str) -> Optional[Dict]:
    """
    Connects to a MongoDB database and retrieves information about a specific hotel.

    Args:
        hotel_name (str): The name of the hotel to search for.

    Returns:
        Optional[Dict]: A dictionary containing the hotel's information, or None if the hotel was not found.

    Raises:
        ValueError: If the connection string or database name or collection name is not found in environment variables.
        Exception: If any error occurs while connecting to the database or retrieving the data.
    """
    connection_string = os.getenv("MONGO_CONNECTION_STRING")
    if not connection_string:
        raise ValueError("No connection string found. Please add MONGO_CONNECTION_STRING to your environment variables.")

    database_name = os.getenv("MONGO_DATABASE_NAME")
    if not database_name:
        raise ValueError("No database name found. Please add MONGO_DATABASE_NAME to your environment variables.")

    collection_name = os.getenv("MONGO_COLLECTION_NAME")
    if not collection_name:
        raise ValueError("No collection name found. Please add MONGO_COLLECTION_NAME to your environment variables.")    

    try:
        client = MongoClient(connection_string)
        database = client[database_name]
        collection = database[collection_name]

        hotel_info = collection.find_one({"name": hotel_name})

        if hotel_info is not None:
            # Convertir ObjectId y otros tipos BSON a str para serializaci√≥n JSON
            hotel_info = json.loads(json.dumps(hotel_info, default=str))

        return hotel_info
    except Exception as e:
        raise Exception(f"An error occurred while retrieving the hotel information: {e}")

schema = {
    "name": "get_hotel_info",
    "description": "Retrieves information about a specific hotel from a MongoDB database.",
    "postprocess": False,
    "parameters": {
        "type": "object",
        "properties": {
            "hotel_name": {
                "type": "string",
                "description": "The name of the hotel to search for."
            }
        },
        "required": ["hotel_name"]
    }
}
```

### Tipos de Herramientas

1. **Herramientas Est√°ticas**: Definidas en archivos Python en `/tools/`
2. **Herramientas Din√°micas**: Creadas en tiempo de ejecuci√≥n desde la interfaz
3. **Herramientas Generadas**: Creadas autom√°ticamente por la IA

## üîí Seguridad y Consideraciones

- **Aislamiento**: Las herramientas se ejecutan en el mismo contexto que la aplicaci√≥n
- **Validaci√≥n**: Los par√°metros se validan seg√∫n el schema antes de la ejecuci√≥n
- **Credenciales**: Las API keys se almacenan en `.env` y se acceden v√≠a `os.getenv()`
- **Control**: Las herramientas deben estar expl√≠citamente activadas para ser usadas
- **Granularidad**: Control individual de post-procesado por herramienta
- **Logging**: Todas las ejecuciones quedan registradas para auditor√≠a
- **Manejo de errores**: Las excepciones son capturadas y documentadas para evitar fallos en cascada

## üîç Soluci√≥n de Problemas Comunes

### Problemas de Importaci√≥n de M√≥dulos

Si se encuentran errores como `ModuleNotFoundError: No module named 'X'`:

1. Verificar que la aplicaci√≥n se ejecuta dentro del entorno virtual correcto
2. Utilizar `python -m streamlit run streamlit_app.py` para asegurar el entorno correcto
3. Comprobar que todas las dependencias est√°n instaladas con `pip install -r requirements.txt`

### Integraci√≥n con MongoDB y errores de BSON

Los problemas con MongoDB y BSON (como `cannot import name 'SON' from 'bson'`) pueden resolverse:

1. Desinstalando el paquete `bson` independiente: `pip uninstall bson`
2. Usando PyMongo 4.6.1 o superior: `pip install pymongo==4.6.1`
3. Serializando ObjectId y otros tipos BSON mediante:
   ```python
   json.loads(json.dumps(mongo_object, default=str))
   ```
   en lugar de depender de m√≥dulos como `bson.json_util`

### Variables de Entorno no Disponibles

Si las variables de entorno no est√°n disponibles para las herramientas:

1. Verificar que existen en el archivo `.env`
2. Usar `env_manager.reload_env_variables()` para cargarlas en tiempo de ejecuci√≥n
3. Comprobar que se invoca `load_dotenv()` al inicio de cada herramienta que las requiere

## üöÄ Estado Actual y Pr√≥ximos Pasos

### Implementado

- ‚úÖ Interfaz de chat funcional con modelos GPT-4, GPT-4-Turbo y GPT-3.5-Turbo
- ‚úÖ Panel de administraci√≥n completo con gesti√≥n visual
- ‚úÖ Sistema de herramientas modulares con carga din√°mica
- ‚úÖ Integraci√≥n con MongoDB para herramientas de acceso a datos
- ‚úÖ Creaci√≥n din√°mica de herramientas con UI dedicada
- ‚úÖ Generaci√≥n autom√°tica con IA y detecci√≥n de variables
- ‚úÖ Control de activaci√≥n y post-procesado por herramienta
- ‚úÖ Prompts especializados para function calling
- ‚úÖ Interfaz mejorada con paginaci√≥n y feedback visual
- ‚úÖ Logging multinivel y exportaci√≥n en m√∫ltiples formatos
- ‚úÖ Sistema de diagn√≥stico avanzado con logs detallados

### En Desarrollo

- üîÑ Persistencia en base de datos (SQLite/PostgreSQL)
- üîÑ Autenticaci√≥n y control de acceso
- üîÑ Herramienta CLI para gesti√≥n
- üîÑ Editor visual de herramientas
- üîÑ Tests unitarios para validaci√≥n autom√°tica

### Planificado

- üìÖ Encadenamiento de herramientas (toolchains)
- üìÖ Soporte para otros proveedores LLM (Claude, Gemini)
- üìÖ Despliegue containerizado (Docker/Kubernetes)
- üìÖ Marketplace de herramientas
- üìÖ API REST para integraci√≥n con otros sistemas
- üìÖ Agentes aut√≥nomos con herramientas auto-evolutivas

---

Este documento define el **contexto t√©cnico y arquitectura global** del proyecto OpenAI Modular MCP. Se recomienda mantenerlo actualizado como referencia base para el desarrollo, documentaci√≥n t√©cnica e integraciones futuras.